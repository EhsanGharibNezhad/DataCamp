{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Statistical Thinking in Python (Part 1)**\n",
    "\n",
    "**Course Description**\n",
    "\n",
    "After all of the hard work of acquiring data and getting them into a form you can work with, you ultimately want to make clear, succinct conclusions from them. This crucial last step of a data analysis pipeline hinges on the principles of statistical inference. In this course, you will start building the foundation you need to think statistically, to speak the language of your data, to understand what they are telling you. The foundations of statistical thinking took decades upon decades to build, but they can be grasped much faster today with the help of computers. With the power of Python-based tools, you will rapidly get up to speed and begin thinking statistically by the end of this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint as pp\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas Configuration Options**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 200)\n",
    "pd.set_option('max_rows', 300)\n",
    "pd.set_option('display.expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Files Location**\n",
    "\n",
    "* Most data files for the exercises can be found on the [course site](https://www.datacamp.com/courses/statistical-thinking-in-python-part-1)\n",
    "    * [2008 election results (all states)](https://assets.datacamp.com/production/repositories/469/datasets/8fb59b9a99957c3b9b1c82b623aea54d8ccbcd9f/2008_all_states.csv)\n",
    "    * [2008 election results (swing states)](https://assets.datacamp.com/production/repositories/469/datasets/e079fddb581197780e1a7b7af2aeeff7242535f0/2008_swing_states.csv)\n",
    "    * [Belmont Stakes](https://assets.datacamp.com/production/repositories/469/datasets/7507bfed990379f246b4f166ea8a57ecf31c6c9d/belmont.csv)\n",
    "    * [Speed of light](https://assets.datacamp.com/production/repositories/469/datasets/df23780d215774ff90be0ea93e53f4fb5ebbade8/michelson_speed_of_light.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data File Objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path.cwd() / 'data' / 'statistical_thinking_1'\n",
    "elections_all_file = data / '2008_all_states.csv'\n",
    "elections_swing_file = data / '2008_swing_states.csv'\n",
    "belmont_file = data / 'belmont.csv'\n",
    "sol_file = data / 'michelson_speed_of_light.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iris Data Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=np.c_[iris['data'], iris['target']], columns=iris['feature_names'] + ['target'])\n",
    "\n",
    "def iris_typing(x):\n",
    "    types = {0.0: 'setosa',\n",
    "             1.0: 'versicolour',\n",
    "             2.0: 'virginica'}\n",
    "    return types[x]\n",
    "\n",
    "iris_df['species'] = iris_df.target.apply(iris_typing)\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical exploratory data analysis\n",
    "\n",
    "Look before you leap! A very important proverb, indeed. Prior to diving in headlong into sophisticated statistical inference techniques, you should first explore your data by plotting them and computing simple summary statistics. This process, called exploratory data analysis, is a crucial first step in statistical analysis of data. So it is a fitting subject for the first chapter of Statistical Thinking in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to exploratory data analysis\n",
    "\n",
    "* Exploring the data is a crucial step of the analysis.\n",
    "    * Organizing\n",
    "    * Plotting\n",
    "    * Computing numerical summaries\n",
    "* This idea is known as exploratory data analysis (EDA)\n",
    "* \"Exploratory data analysis can never be the whole story, but nothing else can serve as the foundation stone.\" - [John Tukey](https://en.wikipedia.org/wiki/John_Tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swing = pd.read_csv(elections_swing_file)\n",
    "swing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The raw data isn't particularly informative\n",
    "* We could start computing parameters and their confidence intervals and do hypothesis test...\n",
    "* ...however, we should graphically explore the data first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tukey's comments on EDA\n",
    "\n",
    "Even though you probably have not read Tukey's book, I suspect you already have a good idea about his viewpoint from the video introducing you to exploratory data analysis. Which of the following quotes is not directly from Tukey?\n",
    "\n",
    "1. Exploratory data analysis is detective work.\n",
    "1. There is no excuse for failing to plot and look.\n",
    "1. The greatest value of a picture is that it forces us to notice what we never expected to see.\n",
    "1. It is important to understand what you can do before you learn how to measure how well you seem to have done it.\n",
    "1. ~~**Often times EDA is too time consuming, so it is better to jump right in and do your hypothesis tests.**~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of graphical EDA\n",
    "\n",
    "Which of the following is not true of graphical EDA?\n",
    "\n",
    "1. It often involves converting tabular data into graphical form.\n",
    "1. If done well, graphical representations can allow for more rapid interpretation of data.\n",
    "1. ~~**A nice looking plot is always the end goal of a statistical analysis.**~~\n",
    "1. There is no excuse for neglecting to do graphical EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting a histogram\n",
    "\n",
    "* always label the axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = [x for x in range(0, 110, 10)]\n",
    "plt.hist(x=swing.dem_share, bins=bin_edges, edgecolor='black')\n",
    "plt.xticks(bin_edges)\n",
    "plt.yticks(bin_edges[:-1])\n",
    "plt.xlabel('Percent of vote for Obama')\n",
    "plt.ylabel('Number of Counties')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seaborn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x=swing.dem_share)\n",
    "plt.xlabel('Percent of vote for Obama')\n",
    "plt.ylabel('Number of Counties')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting a histogram of iris data\n",
    "\n",
    "For the exercises in this section, you will use a classic data set collected by botanist Edward Anderson and made famous by Ronald Fisher, one of the most prolific statisticians in history. Anderson carefully measured the anatomical properties of samples of three different species of iris, *Iris setosa*, *Iris versicolor*, and *Iris virginica*. The full data set is [available as part of scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html). Here, you will work with his measurements of petal length.\n",
    "\n",
    "Plot a histogram of the petal lengths of his 50 samples of Iris versicolor using matplotlib/seaborn's default settings. Recall that to specify the default seaborn style, you can use `sns.set()`, where `sns` is the alias that `seaborn` is imported as.\n",
    "\n",
    "The subset of the data set containing the Iris versicolor petal lengths in units of centimeters (cm) is stored in the NumPy array `versicolor_petal_length`.\n",
    "\n",
    "In the video, Justin plotted the histograms by using the `pandas` library and indexing the DataFrame to extract the desired column. Here, however, you only need to use the provided NumPy array. Also, Justin assigned his plotting statements (except for `plt.show()`) to the dummy variable `_`. This is to prevent unnecessary output from being displayed. It is not required for your solutions to these exercises, however it is good practice to use it. Alternatively, if you are working in an interactive environment such as a Jupyter notebook, you could use a `;` after your plotting statements to achieve the same effect. Justin prefers using `_`. Therefore, you will see it used in the solution code.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import `matplotlib.pyplot` and `seaborn` as their usual aliases (`plt` and `sns`).\n",
    "* Use `seaborn` to set the plotting defaults.\n",
    "* Plot a histogram of the Iris versicolor petal lengths using `plt.hist()` and the provided NumPy array `versicolor_petal_length`.\n",
    "* Show the histogram using `plt.show()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versicolor_petal_length = iris_df['petal length (cm)'][iris_df.species == 'versicolour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(versicolor_petal_length)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axis labels!\n",
    "\n",
    "In the last exercise, you made a nice histogram of petal lengths of Iris versicolor, but **you didn't label the axes!** That's ok; it's not your fault since we didn't ask you to. Now, add axis labels to the plot using `plt.xlabel()` and `plt.ylabel()`. Don't forget to add units and assign both statements to `_`. The packages `matplotlib.pyplot` and `seaborn` are already imported with their standard aliases. This will be the case in what follows, unless specified otherwise.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Label the axes. Don't forget that you should always include units in your axis labels. Your y-axis label is just `'count'`. Your x-axis label is `'petal length (cm)'`. The units are essential!\n",
    "* Display the plot constructed in the above steps using `plt.show()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(versicolor_petal_length)\n",
    "plt.xlabel('petal length (cm)')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting the number of bins in a histogram\n",
    "\n",
    "The histogram you just made had ten bins. This is the default of matplotlib. The \"square root rule\" is a commonly-used rule of thumb for choosing number of bins: choose the number of bins to be the square root of the number of samples. Plot the histogram of Iris versicolor petal lengths again, this time using the square root rule for the number of bins. You specify the number of bins using the `bins` keyword argument of `plt.hist()`.\n",
    "\n",
    "The plotting utilities are already imported and the seaborn defaults already set. The variable you defined in the last exercise, `versicolor_petal_length`, is already in your namespace.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import `numpy` as `np`. This gives access to the square root function, `np.sqrt()`.\n",
    "* Determine how many data points you have using `len()`.\n",
    "* Compute the number of bins using the square root rule.\n",
    "* Convert the number of bins to an integer using the built in `int()` function.\n",
    "* Generate the histogram and make sure to use the `bins` keyword argument.\n",
    "* Hit 'Submit Answer' to plot the figure and see the fruit of your labors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number of data points: n_data\n",
    "n_data = len(versicolor_petal_length)\n",
    "\n",
    "# Number of bins is the square root of number of data points: n_bins\n",
    "n_bins = np.sqrt(n_data)\n",
    "\n",
    "# Convert number of bins to integer: n_bins\n",
    "n_bins = int(n_bins)\n",
    "\n",
    "# Plot the histogram\n",
    "_ = plt.hist(versicolor_petal_length, bins=n_bins)\n",
    "\n",
    "# Label axes\n",
    "_ = plt.xlabel('petal length (cm)')\n",
    "_ = plt.ylabel('count')\n",
    "\n",
    "# Show histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting all of your data: Bee swarm plots\n",
    "\n",
    "* Binning Bias: The same data may be interpreted differently depending on choice of bins\n",
    "* Additionally, all of the data isn't being plotted; the precision of the actual data is lost in the bins\n",
    "* These issues can be resolved with swarm plots\n",
    "    * Point position along the y-axis is the quantitative information\n",
    "    * The data are spread in x to make them visible, but their precise location along the x-axis is unimportant\n",
    "    * No binning bias and all the data are displayed.\n",
    "    * Seaborn & Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(x='state', y='dem_share', data=swing)\n",
    "plt.xlabel('state')\n",
    "plt.ylabel('percent of vote for Obama')\n",
    "plt.title('% of Vote per Swing State County')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bee swarm plot\n",
    "\n",
    "Make a bee swarm plot of the iris petal lengths. Your x-axis should contain each of the three species, and the y-axis the petal lengths. A data frame containing the data is in your namespace as `df`.\n",
    "\n",
    "For your reference, the code Justin used to create the bee swarm plot in the video is provided below:\n",
    "\n",
    "```python\n",
    "_ = sns.swarmplot(x='state', y='dem_share', data=df_swing)\n",
    "_ = plt.xlabel('state')\n",
    "_ = plt.ylabel('percent of vote for Obama')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "In the IPython Shell, you can use `sns.swarmplot`? or `help(sns.swarmplot)` for more details on how to make bee swarm plots using seaborn.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* In the IPython Shell, inspect the DataFrame `df` using `df.head()`. This will let you identify which column names you need to pass as the `x` and `y` keyword arguments in your call to `sns.swarmplot()`.\n",
    "* Use `sns.swarmplot()` to make a bee swarm plot from the DataFrame containing the Fisher iris data set, `df`. The x-axis should contain each of the three species, and the y-axis should contain the petal lengths.\n",
    "* Label the axes.\n",
    "* Show your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(x='species', y='petal length (cm)', data=iris_df)\n",
    "plt.xlabel('species')\n",
    "plt.ylabel('petal length (cm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting a bee swarm plot\n",
    "\n",
    "Which of the following conclusions could you draw from the bee swarm plot of iris petal lengths you generated in the previous exercise? For your convenience, the bee swarm plot is regenerated and shown to the right.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Possible Answers\n",
    "1. All I. versicolor petals are shorter than I. virginica petals.\n",
    "1. I. setosa petals have a broader range of lengths than the other two species.\n",
    "1. __**I. virginica petals tend to be the longest, and I. setosa petals tend to be the shortest of the three species.**__\n",
    "1. I. versicolor is a hybrid of I. virginica and I. setosa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting all of your data: Empirical cumulative distribution functions\n",
    "\n",
    "* x-value of an ECDF is the quantity being measured\n",
    "* y-value is the fraction of data points that have a value smaller than the corresponding x-value\n",
    "* Shows all the data and gives a complete picture of how the data are distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.sort(swing['dem_share'])\n",
    "y = np.arange(1, len(x)+1) / len(x)\n",
    "\n",
    "plt.plot(x, y, marker='.', linestyle='none')\n",
    "plt.xlabel('percent of vote for Obama')\n",
    "plt.ylabel('ECDF')\n",
    "plt.margins(0.02)  # keep data off plot edges\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.margins(0.05)           # Default margin is 0.05, value 0 means fit\n",
    "\n",
    "x = np.sort(swing['dem_share'])\n",
    "y = np.arange(1, len(x)+1) / len(x)\n",
    "\n",
    "ax.plot(x, y, marker='.', linestyle='none')\n",
    "plt.xlabel('percent of vote for Obama')\n",
    "plt.ylabel('ECDF')\n",
    "\n",
    "ax.annotate('20% of counties had <= 36% vote for Obama', xy=(36, .2),\n",
    "            xytext=(40, 0.1), fontsize=10, arrowprops=dict(arrowstyle=\"->\", color='b'))\n",
    "\n",
    "ax.annotate('75% of counties had < 0.5 vote for Obama', xy=(50, .75),\n",
    "            xytext=(55, 0.6), fontsize=10, arrowprops=dict(arrowstyle=\"->\", color='b'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot multiple ECDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.margins(0.05)           # Default margin is 0.05, value 0 means fit\n",
    "\n",
    "for state in swing.state.unique():\n",
    "    x = np.sort(swing['dem_share'][swing.state == state])\n",
    "    y = np.arange(1, len(x)+1) / len(x)\n",
    "    ax.plot(x, y, marker='.', linestyle='none', label=state)\n",
    "\n",
    "plt.xlabel('percent of vote for Obama')\n",
    "plt.ylabel('ECDF')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the ECDF\n",
    "\n",
    "In this exercise, you will write a function that takes as input a 1D array of data and then returns the `x` and `y` values of the ECDF. You will use this function over and over again throughout this course and its sequel. ECDFs are among the most important plots in statistical analysis. You can write your own function, `foo(x,y)` according to the following skeleton:\n",
    "\n",
    "```python\n",
    "def foo(a,b):\n",
    "    \"\"\"State what function does here\"\"\"\n",
    "    # Computation performed here\n",
    "    return x, y\n",
    "```\n",
    "    \n",
    "The function `foo()` above takes two arguments `a` and `b` and returns two values `x` and `y`. The function header `def foo(a,b):` contains the function signature `foo(a,b)`, which consists of the function name, along with its parameters. For more on writing your own functions, see [DataCamp's course Python Data Science Toolbox (Part 1)](https://www.datacamp.com/courses/python-data-science-toolbox-part-1)!\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Define a function with the signature `ecdf(data)`. Within the function definition,\n",
    "    * Compute the number of data points, `n`, using the `len()` function.\n",
    "    * The **x**-values are the sorted data. Use the `np.sort()` function to perform the sorting.\n",
    "    * The **y** data of the ECDF go from `1/n` to `1` in equally spaced increments. You can construct this using `np.arange()`. Remember, however, that the end value in `np.arange()` is not inclusive.  Therefore, `np.arange()` will need to go from `1` to `n+1`. Be sure to divide this by `n`.\n",
    "    * The function returns the values `x` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\"\n",
    "    # Number of data points: n\n",
    "    n = len(data)\n",
    "\n",
    "    # x-data for the ECDF: x\n",
    "    x = np.sort(data)\n",
    "\n",
    "    # y-data for the ECDF: y\n",
    "    y = np.arange(1, n+1) / n\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the ECDF\n",
    "\n",
    "You will now use your `ecdf()` function to compute the ECDF for the petal lengths of Anderson's *Iris versicolor* flowers. You will then plot the ECDF. Recall that your `ecdf()` function returns two arrays so you will need to unpack them. An example of such unpacking is `x, y = foo(data)`, for some function `foo()`.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Use `ecdf()` to compute the ECDF of `versicolor_petal_length`. Unpack the output into `x_vers` and `y_vers`.\n",
    "* Plot the ECDF as dots. Remember to include `marker = '.'` and `linestyle = 'none'` in addition to `x_vers` and `y_vers` as arguments inside `plt.plot()`.\n",
    "* Label the axes. You can label the y-axis `'ECDF'`.\n",
    "* Show your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ECDF for versicolor data: x_vers, y_vers\n",
    "x, y = ecdf(versicolor_petal_length)\n",
    "\n",
    "# Generate plot\n",
    "plt.plot(x, y, marker='.', linestyle='none')\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Versicolor Petal Length (cm)')\n",
    "plt.ylabel('ECDF')\n",
    "\n",
    "# Display the plot\n",
    "plt.margins(0.02)  # keep data off plot edges\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of ECDFs\n",
    "\n",
    "ECDFs also allow you to compare two or more distributions (though plots get cluttered if you have too many). Here, you will plot ECDFs for the petal lengths of all three iris species. You already wrote a function to generate ECDFs so you can put it to good use!\n",
    "\n",
    "To overlay all three ECDFs on the same plot, you can use `plt.plot()` three times, once for each ECDF. Remember to include `marker='.'` and `linestyle='none'` as arguments inside `plt.plot()`.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Compute ECDFs for each of the three species using your `ecdf()` function. The variables `setosa_petal_length`, `versicolor_petal_length`, and `virginica_petal_length` are all in your namespace. Unpack the ECDFs into `x_set`, `y_set`, `x_vers`, `y_vers` and `x_virg`, `y_virg`, respectively.\n",
    "* Plot all three ECDFs on the same plot as dots. To do this, you will need three `plt.plot()` commands. Assign the result of each to `_`.\n",
    "* A legend and axis labels have been added for you, so hit 'Submit Answer' to see all the ECDFs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virginica_petal_length = iris_df['petal length (cm)'][iris_df.species == 'virginica']\n",
    "setosa_petal_length = iris_df['petal length (cm)'][iris_df.species == 'setosa']\n",
    "\n",
    "# Compute ECDFs\n",
    "x_set, y_set = ecdf(setosa_petal_length)\n",
    "x_vers, y_vers = ecdf(versicolor_petal_length)\n",
    "x_virg, y_virg = ecdf(virginica_petal_length)\n",
    "\n",
    "# Plot all ECDFs on the same plot\n",
    "plt.plot(x_set, y_set, marker='.', linestyle='none')\n",
    "plt.plot(x_vers, y_vers, marker='.', linestyle='none')\n",
    "plt.plot(x_virg, y_virg, marker='.', linestyle='none')\n",
    "\n",
    "# Annotate the plot\n",
    "plt.legend(('setosa', 'versicolor', 'virginica'), loc='lower right')\n",
    "_ = plt.xlabel('petal length (cm)')\n",
    "_ = plt.ylabel('ECDF')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onward toward the whole story\n",
    "\n",
    "* Start with graphical eda!\n",
    "\n",
    "**Coming up...**\n",
    "\n",
    "* Thinking probabilistically\n",
    "* Discrete and continuous distributions\n",
    "* The power of hacker statistics using np.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative exploratory data analysis\n",
    "\n",
    "In the last chapter, you learned how to graphically explore data. In this chapter, you will compute useful summary statistics, which serve to concisely describe salient features of a data set with a few numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to summary statistics: The sample mean and median\n",
    "\n",
    "* mean - average\n",
    "    * heavily influenced by outliers\n",
    "    * `np.mean()`\n",
    "* median - middle value of the sorted dataset\n",
    "    * immune to outlier influence\n",
    "    * `np.median()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Means and medians\n",
    "\n",
    "Which one of the following statements is true about means and medians?\n",
    "\n",
    "**Possible Answers**\n",
    "\n",
    "* ~~An outlier can significantly affect the value of both the mean and the median.~~\n",
    "* **An outlier can significantly affect the value of the mean, but not the median.**\n",
    "* ~~Means and medians are in general both robust to single outliers.~~\n",
    "* ~~The mean and median are equal if there is an odd number of data points.~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing means\n",
    "\n",
    "The mean of all measurements gives an indication of the typical magnitude of a measurement. It is computed using `np.mean()`.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Compute the mean petal length of Iris versicolor from Anderson's classic data set. The variable `versicolor_petal_length` is provided in your namespace. Assign the mean to `mean_length_vers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean: mean_length_vers\n",
    "mean_length_vers = np.mean(versicolor_petal_length)\n",
    "\n",
    "# Print the result with some nice formatting\n",
    "print('I. versicolor:', mean_length_vers, 'cm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with pandas.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.groupby(['species']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentiles, outliers and box plots\n",
    "\n",
    "* The median is a special name for the 50th percentile\n",
    "    * 50% of the data are less than the median\n",
    "* The 25th percentile is the value of the data point that is greater than 25% of the sorted data\n",
    "* percentiles are useful summary statistics and can be computed using `np.percentile()`\n",
    "\n",
    "**Computing Percentiles**\n",
    "\n",
    "```python\n",
    "np.percentile(df_swing['dem_share'], [25, 50, 75])\n",
    "```\n",
    "\n",
    "![](https://raw.githubusercontent.com/trenton3983/DataCamp/master/Images/statistical_thinking_1/box_plot.JPG)\n",
    "\n",
    "* Box plots are a graphical methode for displying summary statistics\n",
    "    * median is the middle line: 50th percentile\n",
    "    * bottom and top line of the box represent the 25th & 75th percentile, repectively\n",
    "    * the space between the 25th and 75th percentile is the interquartile range (IQR)\n",
    "    * Whiskers extent a distance of 1.5 time the IQR, or the extent of the data, whichever is less extreme\n",
    "    * Any points outside the whiskers are plotted as individual points, which we demarcate as outliers\n",
    "        * There is no single definition for an outlier, however, being more than 2 IQRs away from the median is a common criterion.\n",
    "        * An outlier is not necessarily erroneous\n",
    "    * Box plots are a great alternative to bee swarm plots, becasue bee swarm plots become too cluttered with large data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = pd.read_csv(elections_all_file)\n",
    "all_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='east_west', y='dem_share', data=all_states)\n",
    "plt.xlabel('region')\n",
    "plt.ylabel('percent of vote for Obama')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing percentiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing percentiles to ECDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box-and-whisker plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance and standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The standard deviation and the variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance and Pearson correlation coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance and covariance by looking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Pearson correlation coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking probabilistically-- Discrete variables\n",
    "\n",
    "Statistical inference rests upon probability. Because we can very rarely say anything meaningful with absolute certainty from data, we use probabilistic language to make quantitative statements about data. In this chapter, you will learn how to think probabilistically about discrete quantities, those that can only take certain values, like integers. It is an important first step in building the probabilistic language necessary to think statistically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic logic and statistical inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the goal of statistical inference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we use the language of probablility?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random number generators and hacker statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating random numbers using the np.random module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The np.random module and Bernoulli trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many defaults might we expect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will the bank fail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability distributions and stories: The Binomial distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling out of the Binomial distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Binomial PMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson processes and the Poisson distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between Binomial and Poisson distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many no-hitters in a season?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Was 2015 anomalous?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking probabilistically-- Continuous variables\n",
    "\n",
    "In the last chapter, you learned about probability distributions of discrete variables. Now it is time to move on to continuous variables, such as those that can take on any fractional value. Many of the principles are the same, but there are some subtleties. At the end of this last chapter of the course, you will be speaking the probabilistic language you need to launch into the inference techniques covered in the sequel to this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability density functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting CDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the Normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Normal PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Normal CDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Normal distribution: Properties and warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gauss and the 10 Deutschmark banknote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the Belmont Stakes results Normally distributed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the chances of a horse matching or beating Secretariat's record?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Exponential distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching a story and a distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waiting for the next Secretariat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you have a story, you can simulate it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of no-hitters and cycles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final thoughts and encouragement toward Statistical Thinking II"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
