{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint as pp\n",
    "import csv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas Configuration Options**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 200)\n",
    "pd.set_option('max_rows', 300)\n",
    "pd.set_option('display.expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Files Location**\n",
    "\n",
    "* Most data files for the exercises can be found on the [course site](https://www.datacamp.com/courses/merging-dataframes-with-pandas)\n",
    "    * [Baby Names](https://assets.datacamp.com/production/repositories/516/datasets/43c9b6bf4c283ab024b2d7d61fbf15a0baa1e44d/Baby%20names.zip)\n",
    "    * [Summer Olympic Medals](https://assets.datacamp.com/production/repositories/516/datasets/2d14df8d3c6a1773358fa000f203282c2e1107d6/Summer%20Olympic%20medals.zip)\n",
    "    * [Automobile Fuel Efficiency](https://assets.datacamp.com/production/repositories/516/datasets/2f3d8b2156d5669fb7e12137f1c2e979c3c9ce0b/automobiles.csv)\n",
    "    * [Exchange Rates](https://assets.datacamp.com/production/repositories/516/datasets/e91482db6a7bae394653278e4e908e63ed9ac833/exchange.csv)\n",
    "    * [GDP](https://assets.datacamp.com/production/repositories/516/datasets/a0858a700501f88721ca9e4bdfca99b9e10b937f/GDP.zip)\n",
    "    * [Oil Prices](https://assets.datacamp.com/production/repositories/516/datasets/707566cf46c4dd6290b9029f5e07a92baf3fe3f7/oil_price.csv)\n",
    "    * [Pittsburgh Weather](https://assets.datacamp.com/production/repositories/516/datasets/58c1ead59818b2451324e9e84239db7bda6b11d3/pittsburgh2013.csv)\n",
    "    * [Sales](https://assets.datacamp.com/production/repositories/516/datasets/2b89c1b00016e1ebcfd7f08a127d2c79589ce5c0/Sales.zip)\n",
    "    * [S&P 500](https://assets.datacamp.com/production/repositories/516/datasets/7a9b570a02ef589891d9576a86876a616ca5f3c8/sp500.csv)\n",
    "* Other data files may be found in my [DataCamp repository](https://github.com/trenton3983/DataCamp/tree/master/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data File Objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path.cwd() / 'data'\n",
    "auto_fuel_file = data / 'auto_fuel_efficiency.csv'\n",
    "baby_1881_file = data / 'baby_names1881.csv'\n",
    "baby_1981_file = data / 'baby_names1981.csv'\n",
    "exch_rates_file = data / 'exchange_rates.csv'\n",
    "gdp_china_file = data / 'gdp_china.csv'\n",
    "gdp_usa_file = data / 'gdp_usa.csv'\n",
    "oil_price_file = data / 'oil_price.csv'\n",
    "pitts_file = data / 'pittsburgh_weather_2013.csv'\n",
    "sales_feb_hardware_file = data / 'sales-feb-Hardware.csv'\n",
    "sales_feb_service_file = data / 'sales-feb-Service.csv'\n",
    "sales_feb_software_file = data / 'sales-feb-Software.csv'\n",
    "sales_jan_2015_file = data / 'sales-jan-2015.csv'\n",
    "sales_feb_2015_file = data / 'sales-feb-2015.csv'\n",
    "sales_mar_2015_file = data / 'sales-mar-2015.csv'\n",
    "sp500_file = data / 'sp500.csv'\n",
    "so_bronze_file = data / 'summer_olympics_Bronze.csv'\n",
    "so_bronze5_file = data / 'summer_olympics_bronze_top5.csv'\n",
    "so_gold_file = data / 'summer_olympics_Gold.csv'\n",
    "so_gold5_file = data / 'summer_olympics_gold_top5.csv'\n",
    "so_silver_file = data / 'summer_olympics_Silver.csv'\n",
    "so_silver5_file = data / 'summer_olympics_silver_top5.csv'\n",
    "so_all_medalists_file = data / 'summer_olympics_medalists 1896 to 2008 - ALL MEDALISTS.tsv'\n",
    "so_editions_file = data / 'summer_olympics_medalists 1896 to 2008 - EDITIONS.tsv'\n",
    "so_ioc_codes_file = data / 'summer_olympics_medalists 1896 to 2008 - IOC COUNTRY CODES.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Merging DataFrames with pandas\n",
    "\n",
    "***Course Description***\n",
    "\n",
    "As a Data Scientist, you'll often find that the data you need is not in a single file. It may be spread across a number of text files, spreadsheets, or databases. You want to be able to import the data of interest as a collection of DataFrames and figure out how to combine them to answer your central questions. This course is all about the act of combining, or merging, DataFrames, an essential part of any working Data Scientist's toolbox. You'll hone your pandas skills by learning how to organize, reshape, and aggregate multiple data sets to answer your specific questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Preparing Data\n",
    "\n",
    "In this chapter, you'll learn about different techniques you can use to import multiple files into DataFrames. Having imported your data into individual DataFrames, you'll then learn how to share information between DataFrames using their Indexes. Understanding how Indexes work is essential information that you'll need for merging DataFrames later in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Reading multiple data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools for pandas data import\n",
    "\n",
    "* pd.read_csv() for CSV files\n",
    "    * dataframe = pd.read_csv(filepath)\n",
    "    * dozens of optional input parameters\n",
    "* Other data import tools:\n",
    "    * pd.read_excel()\n",
    "    * pd.read_html()\n",
    "    * pd.read_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading separate files\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "dataframe0 = pd.read_csv('sales-jan-2015.csv')\n",
    "dataframe1 = pd.read_csv('sales-feb-2015.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a loop\n",
    "\n",
    "```python\n",
    "filenames = ['sales-jan-2015.csv', 'sales-feb-2015.csv']\n",
    "dataframes = []\n",
    "for f in filenames:\n",
    "    dataframes.append(pd.read_csv(f))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a comprehension\n",
    "\n",
    "```python\n",
    "filenames = ['sales-jan-2015.csv', 'sales-feb-2015.csv']\n",
    "dataframes = [pd.read_csv(f) for f in filenames]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using glob\n",
    "\n",
    "```python\n",
    "from glob import glob\n",
    "filenames = glob('sales*.csv')\n",
    "dataframes = [pd.read_csv(f) for f in filenames]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading DataFrames from multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading DataFrames from multiple files in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining DataFrames from multiple data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindexing DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Indexes\" vs. \"Indices\"\n",
    "\n",
    "* indices: many index labels within Index data structures\n",
    "* indexes: many pandas Index data structures\n",
    "\n",
    "![](https://raw.githubusercontent.com/trenton3983/DataCamp/master/Images/merging_dataframes_in_python/indices_indexes.JPG \"Indices & Indexes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing weather data\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "w_mean = pd.read_csv('quarterly_mean_temp.csv', index_col='Month')\n",
    "w_max = pd.read_csv('quarterly_max_temp.csv', index_col='Month')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining the data\n",
    "\n",
    "```python\n",
    "print(w_mean)\n",
    "        Mean TemperatureF\n",
    "Month\n",
    "Apr     61.956044\n",
    "Jan     32.133333\n",
    "Jul     68.934783\n",
    "Oct     43.434783\n",
    "\n",
    "print(w_max)\n",
    "        Max TemperatureF\n",
    "Month\n",
    "Jan     68\n",
    "Apr     89\n",
    "Jul     91\n",
    "Oct     84\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The DataFrame indexes\n",
    "\n",
    "```python\n",
    "print(w_mean.index)\n",
    "Index(['Apr', 'Jan', 'Jul', 'Oct'], dtype='object', name='Month')\n",
    "\n",
    "print(w_max.index)\n",
    "Index(['Jan', 'Apr', 'Jul', 'Oct'], dtype='object', name='Month')\n",
    "\n",
    "print(type(w_mean.index))\n",
    "<class 'pandas.indexes.base.Index'>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using .reindex()\n",
    "\n",
    "```python\n",
    "ordered = ['Jan', 'Apr', 'Jul', 'Oct']\n",
    "w_mean2 = w_mean.reindex(ordered)\n",
    "print(w_mean2)\n",
    "\n",
    "        Mean TemperatureF\n",
    "Month\n",
    "Jan     32.133333\n",
    "Apr     61.956044\n",
    "Jul     68.934783\n",
    "Oct     43.434783\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using .sort_index()\n",
    "\n",
    "```python\n",
    "w_mean2.sort_index()\n",
    "        Mean TemperatureF\n",
    "Month\n",
    "Apr     61.956044\n",
    "Jan     32.133333\n",
    "Jul     68.934783\n",
    "Oct     43.434783\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reindex from a DataFrame Index\n",
    "\n",
    "```python\n",
    "w_mean.reindex(w_max.index)\n",
    "        Mean TemperatureF\n",
    "Month\n",
    "Jan     32.133333\n",
    "Apr     61.956044\n",
    "Jul     68.934783\n",
    "Oct     43.434783\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reindexing with missing labels\n",
    "\n",
    "```python\n",
    "w_mean3 = w_mean.reindex(['Jan', 'Apr', 'Dec'])\n",
    "print(w_mean3)\n",
    "        Mean TemperatureF\n",
    "Month\n",
    "Jan     32.133333\n",
    "Apr     61.956044\n",
    "Dec     NaN\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reindex from a DataFrame Index\n",
    "\n",
    "```python\n",
    "w_max.reindex(w_mean3.index)\n",
    "        Max TemperatureF\n",
    "Month\n",
    "Jan     68.0\n",
    "Apr     89.0\n",
    "Dec     NaN\n",
    "\n",
    "w_max.reindex(w_mean3.index).dropna()\n",
    "        Max TemperatureF\n",
    "Month\n",
    "Jan     68.0\n",
    "Apr     89.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order matters\n",
    "\n",
    "```python\n",
    "w_max.reindex(w_mean.index)\n",
    "        Max TemperatureF\n",
    "Month\n",
    "Apr     89\n",
    "Jan     68\n",
    "Jul     91\n",
    "Oct     84\n",
    "\n",
    "w_mean.reindex(w_max.index)\n",
    "        Mean TemperatureF\n",
    "Month\n",
    "Jan     32.133333\n",
    "Apr     61.956044\n",
    "Jul     68.934783\n",
    "Oct     43.434783\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting DataFrame with the Index & columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reindexing DataFrame from a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reindexing DataFrame using another DataFrame Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic with Series & DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading weather data\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "weather = pd.read_csv('pittsburgh2013.csv', index_col='Date', parse_dates=True)\n",
    "weather.loc['2013-7-1':'2013-7-7', 'PrecipitationIn']\n",
    "\n",
    "Date\n",
    "2013-07-01 0.18\n",
    "2013-07-02 0.14\n",
    "2013-07-03 0.00\n",
    "2013-07-04 0.25\n",
    "2013-07-05 0.02\n",
    "2013-07-06 0.06\n",
    "2013-07-07 0.10\n",
    "Name: PrecipitationIn, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar multiplication\n",
    "\n",
    "```python\n",
    "weather.loc['2013-07-01':'2013-07-07', 'PrecipitationIn'] * 2.54\n",
    "\n",
    "Date\n",
    "2013-07-01 0.4572\n",
    "2013-07-02 0.3556\n",
    "2013-07-03 0.0000\n",
    "2013-07-04 0.6350\n",
    "2013-07-05 0.0508\n",
    "2013-07-06 0.1524\n",
    "2013-07-07 0.2540\n",
    "Name: PrecipitationIn, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Absolute temperature range\n",
    "\n",
    "```python\n",
    "week1_range = weather.loc['2013-07-01':'2013-07-07', ['Min TemperatureF', 'Max TemperatureF']]\n",
    "print(week1_range)\n",
    "Min TemperatureF Max TemperatureF\n",
    "Date\n",
    "2013-07-01 66 79\n",
    "2013-07-02 66 84\n",
    "2013-07-03 71 86\n",
    "2013-07-04 70 86\n",
    "2013-07-05 69 86\n",
    "2013-07-06 70 89\n",
    "2013-07-07 70 77\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average temperature\n",
    "\n",
    "```python\n",
    "week1_mean = weather.loc['2013-07-01':'2013-07-07', 'Mean TemperatureF']\n",
    "print(week1_mean)\n",
    "Date\n",
    "2013-07-01 72\n",
    "2013-07-02 74\n",
    "2013-07-03 78\n",
    "2013-07-04 77\n",
    "2013-07-05 76\n",
    "2013-07-06 78\n",
    "2013-07-07 72\n",
    "Name: Mean TemperatureF, dtype: int64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relative temperature range\n",
    "\n",
    "```python\n",
    "week1_range / week1_mean\n",
    "RuntimeWarning: Cannot compare type 'Timestamp' with type 'str', sort order is\n",
    "undefined for incomparable objects\n",
    "return this.join(other, how=how, return_indexers=return_indexers)\n",
    "\n",
    "2013-07-01 00:00:00 2013-07-02 00:00:00 2013-07-03 00:00:00 \\\n",
    "Date\n",
    "2013-07-01 NaN NaN NaN\n",
    "2013-07-02 NaN NaN NaN\n",
    "2013-07-03 NaN NaN NaN\n",
    "2013-07-04 NaN NaN NaN\n",
    "2013-07-05 NaN NaN NaN\n",
    "2013-07-06 NaN NaN NaN\n",
    "2013-07-07 NaN NaN NaN\n",
    "2013-07-04 00:00:00 2013-07-05 00:00:00 2013-07-06 00:00:00 \\\n",
    "Date\n",
    "2013-07-01 NaN NaN NaN\n",
    "... ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relative temperature range\n",
    "\n",
    "```python\n",
    "week1_range.divide(week1_mean, axis='rows')\n",
    "\n",
    "Min TemperatureF Max TemperatureF\n",
    "Date\n",
    "2013-07-01 0.916667 1.097222\n",
    "2013-07-02 0.891892 1.135135\n",
    "2013-07-03 0.910256 1.102564\n",
    "2013-07-04 0.909091 1.116883\n",
    "2013-07-05 0.907895 1.131579\n",
    "2013-07-06 0.897436 1.141026\n",
    "2013-07-07 0.972222 1.069444\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentage changes\n",
    "\n",
    "```python\n",
    "week1_mean.pct_change() * 100\n",
    "\n",
    "Date\n",
    "2013-07-01 NaN\n",
    "2013-07-02 2.777778\n",
    "2013-07-03 5.405405\n",
    "2013-07-04 -1.282051\n",
    "2013-07-05 -1.298701\n",
    "2013-07-06 2.631579\n",
    "2013-07-07 -7.692308\n",
    "Name: Mean TemperatureF, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bronze Olympic medals\n",
    "\n",
    "```python\n",
    "bronze = pd.read_csv('bronze_top5.csv', index_col=0)\n",
    "print(bronze)\n",
    "Total\n",
    "Country\n",
    "United States 1052.0\n",
    "Soviet Union 584.0\n",
    "United Kingdom 505.0\n",
    "France 475.0\n",
    "Germany 454.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Silver Olympic medals\n",
    "\n",
    "```python\n",
    "silver = pd.read_csv('silver_top5.csv', index_col=0)\n",
    "print(silver)\n",
    "Total\n",
    "Country\n",
    "United States 1195.0\n",
    "Soviet Union 627.0\n",
    "United Kingdom 591.0\n",
    "France 461.0\n",
    "Italy 394.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gold Olympic medals\n",
    "\n",
    "```python\n",
    "gold = pd.read_csv('gold_top5.csv', index_col=0)\n",
    "print(gold)\n",
    "Total\n",
    "Country\n",
    "United States 2088.0\n",
    "Soviet Union 838.0\n",
    "United Kingdom 498.0\n",
    "Italy 460.0\n",
    "Germany 407.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding bronze, silver\n",
    "\n",
    "```python\n",
    "bronze + silver\n",
    "\n",
    "Country\n",
    "France 936.0\n",
    "Germany NaN\n",
    "Italy NaN\n",
    "Soviet Union 1211.0\n",
    "United Kingdom 1096.0\n",
    "United States 2247.0\n",
    "Name: Total, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding bronze, silver\n",
    "\n",
    "```python\n",
    "bronze + silver\n",
    "\n",
    "Country\n",
    "France 936.0\n",
    "Germany NaN\n",
    "Italy NaN\n",
    "Soviet Union 1211.0\n",
    "United Kingdom 1096.0\n",
    "United States 2247.0\n",
    "Name: Total, dtype: float64\n",
    "In [22]: print(bronze['United States'])\n",
    "1052.0\n",
    "In [23]: print(silver['United States'])\n",
    "1195.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the .add() method\n",
    "\n",
    "```python\n",
    "bronze.add(silver)\n",
    "\n",
    "Country\n",
    "France 936.0\n",
    "Germany NaN\n",
    "Italy NaN\n",
    "Soviet Union 1211.0\n",
    "United Kingdom 1096.0\n",
    "United States 2247.0\n",
    "Name: Total, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a fill_value\n",
    "\n",
    "```python\n",
    "bronze.add(silver, fill_value=0)\n",
    "\n",
    "Country\n",
    "France 936.0\n",
    "Germany 454.0\n",
    "Italy 394.0\n",
    "Soviet Union 1211.0\n",
    "United Kingdom 1096.0\n",
    "United States 2247.0\n",
    "Name: Total, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding bronze, silver, gold\n",
    "\n",
    "```python\n",
    "bronze + silver + gold\n",
    "\n",
    "Country\n",
    "France NaN\n",
    "Germany NaN\n",
    "Italy NaN\n",
    "Soviet Union 2049.0\n",
    "United Kingdom 1594.0\n",
    "United States 4335.0\n",
    "Name: Total, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chaining .add()\n",
    "\n",
    "```python\n",
    "bronze.add(silver, fill_value=0).add(gold, fill_value=0)\n",
    "\n",
    "Country\n",
    "France 936.0\n",
    "Germany 861.0\n",
    "Italy 854.0\n",
    "Soviet Union 2049.0\n",
    "United Kingdom 1594.0\n",
    "United States 4335.0\n",
    "Name: Total, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding unaligned DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcasting in Arithmetic formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing percentage growth of GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting currency of stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating Data\n",
    "\n",
    "Having learned how to import multiple DataFrames and share information using Indexes, in this chapter you'll learn how to perform database-style operations to combine DataFrames. In particular, you'll learn about appending and concatenating DataFrames while working with a variety of real-world datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending & concatenating Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### append()\n",
    "\n",
    "* .append(): Series & DataFrame method\n",
    "* Invocation:\n",
    "* s1.append(s2)\n",
    "* Stacks rows of s2 below s1\n",
    "* Method for Series & DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concat()\n",
    "\n",
    "* concat(): pandas module function\n",
    "* Invocation:\n",
    "* pd.concat([s1, s2, s3])\n",
    "* Can stack row-wise or column-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concat() & .append()\n",
    "\n",
    "* Equivalence of concat() & .append():\n",
    "* result1 = pd.concat([s1, s2, s3])\n",
    "* result2 = s1.append(s2).append(s3)\n",
    "* result1 == result2 elementwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series of US states\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "northeast = pd.Series(['CT', 'ME', 'MA', 'NH', 'RI', 'VT', 'NJ', 'NY', 'PA'])\n",
    "south = pd.Series(['DE', 'FL', 'GA', 'MD', 'NC', 'SC', 'VA', 'DC', 'WV', 'AL', 'KY', 'MS', 'TN', 'AR', 'LA', 'OK', 'TX'])\n",
    "midwest = pd.Series(['IL', 'IN', 'MN', 'MO', 'NE', 'ND', 'SD', 'IA', 'KS', 'MI', 'OH', 'WI'])\n",
    "west = pd.Series(['AZ', 'CO', 'ID', 'MT',\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using .append()\n",
    "\n",
    "```python\n",
    "east = northeast.append(south)\n",
    "print(east)\n",
    "0 CT       7 DC\n",
    "1 ME       8 WV\n",
    "2 MA       9 AL\n",
    "3 NH       10 KY\n",
    "4 RI       11 MS\n",
    "5 VT       12 TN\n",
    "6 NJ       13 AR\n",
    "7 NY       14 LA\n",
    "8 PA       15 OK\n",
    "0 DE       16 TX\n",
    "1 FL       dtype: object\n",
    "2 GA\n",
    "3 MD\n",
    "4 NC\n",
    "5 SC\n",
    "6 VA\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The appended Index\n",
    "\n",
    "```python\n",
    "print(east.index)\n",
    "Int64Index([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], dtype='int64')\n",
    "\n",
    "print(east.loc[3])\n",
    "3 NH\n",
    "3 MD\n",
    "dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using .reset_index()\n",
    "\n",
    "```python\n",
    "new_east = northeast.append(south).reset_index(drop=True)\n",
    "print(new_east.head(11))\n",
    "0 CT\n",
    "1 ME\n",
    "2 MA\n",
    "3 NH\n",
    "4 RI\n",
    "5 VT\n",
    "6 NJ\n",
    "7 NY\n",
    "8 PA\n",
    "9 DE\n",
    "10 FL\n",
    "dtype: object\n",
    "\n",
    "print(new_east.index)\n",
    "RangeIndex(start=0, stop=26, step=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using concat()\n",
    "\n",
    "```python\n",
    "east = pd.concat([northeast, south])\n",
    "print(east.head(11))\n",
    "0 CT\n",
    "1 ME\n",
    "2 MA\n",
    "3 NH\n",
    "4 RI\n",
    "5 VT\n",
    "6 NJ\n",
    "7 NY\n",
    "8 PA\n",
    "0 DE\n",
    "1 FL\n",
    "dtype: object\n",
    "print(east.index)\n",
    "Int64Index([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], dtype='int64')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using ignore_index\n",
    "\n",
    "```python\n",
    "new_east = pd.concat([northeast, south], ignore_index=True)\n",
    "print(new_east.head(11))\n",
    "0 CT\n",
    "1 ME\n",
    "2 MA\n",
    "3 NH\n",
    "4 RI\n",
    "5 VT\n",
    "6 NJ\n",
    "7 NY\n",
    "8 PA\n",
    "9 DE\n",
    "10 FL\n",
    "dtype: object\n",
    "print(new_east.index)\n",
    "RangeIndex(start=0, stop=26, step=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appending Series with nonunique Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appending pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating pandas Series along row axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending & concatenating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading population data\n",
    "\n",
    "```python\n",
    "In [1]: import pandas as pd\n",
    "In [2]: pop1 = pd.read_csv('population_01.csv', index_col=0)\n",
    "In [3]: pop2 = pd.read_csv('population_02.csv', index_col=0)\n",
    "In [4]: print(type(pop1), pop1.shape)\n",
    "<class 'pandas.core.frame.DataFrame'> (4, 1)\n",
    "In [5]: print(type(pop2), pop2.shape)\n",
    "<class 'pandas.core.frame.DataFrame'> (4, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining population data\n",
    "\n",
    "```python\n",
    "print(pop1)\n",
    "2010 Census Population\n",
    "Zip Code ZCTA\n",
    "66407 479\n",
    "72732 4716\n",
    "50579 2405\n",
    "46241 30670\n",
    "print(pop2)\n",
    "\n",
    "2010 Census Population\n",
    "Zip Code ZCTA\n",
    "12776 2180\n",
    "76092 26669\n",
    "98360 12221\n",
    "49464 27481\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appending population DataFrames\n",
    "\n",
    "```python\n",
    "pop1.append(pop2)\n",
    "\n",
    "2010 Census Population\n",
    "Zip Code ZCTA\n",
    "66407 479\n",
    "72732 4716\n",
    "50579 2405\n",
    "46241 30670\n",
    "12776 2180\n",
    "76092 26669\n",
    "98360 12221\n",
    "49464 27481\n",
    "\n",
    "print(pop1.index.name, pop1.columns)\n",
    "Zip Code ZCTA Index(['2010 Census Population'], dtype='object')\n",
    "\n",
    "print(pop2.index.name, pop2.columns)\n",
    "Zip Code ZCTA Index(['2010 Census Population'], dtype='object')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population & unemployment data\n",
    "\n",
    "```python\n",
    "population = pd.read_csv('population_00.csv', index_col=0)\n",
    "unemployment = pd.read_csv('unemployment_00.csv', index_col=0)\n",
    "print(population)\n",
    "2010 Census Population\n",
    "Zip Code ZCTA\n",
    "57538 322\n",
    "59916 130\n",
    "37660 40038\n",
    "2860 45199\n",
    "\n",
    "print(unemployment)\n",
    "unemployment participants\n",
    "Zip\n",
    "2860 0.11 34447\n",
    "46167 0.02 4800\n",
    "1097 0.33 42\n",
    "80808 0.07 4310\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appending population & unemployment\n",
    "\n",
    "```python\n",
    "population.append(unemployment)\n",
    "2010 Census Population participants unemployment\n",
    "57538 322.0 NaN NaN\n",
    "59916 130.0 NaN NaN\n",
    "37660 40038.0 NaN NaN\n",
    "2860 45199.0 NaN NaN\n",
    "2860 NaN 34447.0 0.11\n",
    "46167 NaN 4800.0 0.02\n",
    "1097 NaN 42.0 0.33\n",
    "80808 NaN 4310.0 0.07\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeated index labels\n",
    "\n",
    "```python\n",
    "population.append(unemployment)\n",
    "\n",
    "2010 Census Population participants unemployment\n",
    "57538 322.0 NaN NaN\n",
    "59916 130.0 NaN NaN\n",
    "37660 40038.0 NaN NaN\n",
    "2860 45199.0 NaN NaN\n",
    "2860 NaN 34447.0 0.11\n",
    "46167 NaN 4800.0 0.02\n",
    "1097 NaN 42.0 0.33\n",
    "80808 NaN 4310.0 0.07\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating rows\n",
    "\n",
    "```python\n",
    "pd.concat([population, unemployment], axis=0)\n",
    "\n",
    "2010 Census Population participants unemployment\n",
    "57538 322.0 NaN NaN\n",
    "59916 130.0 NaN NaN\n",
    "37660 40038.0 NaN NaN\n",
    "2860 45199.0 NaN NaN\n",
    "2860 NaN 34447.0 0.11\n",
    "46167 NaN 4800.0 0.02\n",
    "1097 NaN 42.0 0.33\n",
    "80808 NaN 4310.0 0.07\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating columns\n",
    "\n",
    "```python\n",
    "pd.concat([population, unemployment], axis=1)\n",
    "\n",
    "2010 Census Population unemployment participants\n",
    "1097 NaN 0.33 42.0\n",
    "2860 45199.0 0.11 34447.0\n",
    "37660 40038.0 NaN NaN\n",
    "46167 NaN 0.02 4800.0\n",
    "57538 322.0 NaN NaN\n",
    "59916 130.0 NaN NaN\n",
    "80808 NaN 0.07 4310.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appending DataFrames with ignore_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating pandas DataFrames along column axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading multiple files to build a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation, keys & MultiIndexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading rainfall data\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "file1 = 'q1_rainfall_2013.csv'\n",
    "rain2013 = pd.read_csv(file1, index_col='Month', parse_dates=True)\n",
    "file2 = 'q1_rainfall_2014.csv'\n",
    "rain2014 = pd.read_csv(file2, index_col='Month', parse_dates=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining rainfall data\n",
    "\n",
    "```python\n",
    "print(rain2013)\n",
    "Precipitation\n",
    "Month\n",
    "Jan 0.096129\n",
    "Feb 0.067143\n",
    "Mar 0.061613\n",
    "\n",
    "print(rain2014)\n",
    "Precipitation\n",
    "Month\n",
    "Jan 0.050323\n",
    "Feb 0.082143\n",
    "Mar 0.070968\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating rows\n",
    "\n",
    "```python\n",
    "pd.concat([rain2013, rain2014], axis=0)\n",
    "\n",
    "Precipitation\n",
    "Jan 0.096129\n",
    "Feb 0.067143\n",
    "Mar 0.061613\n",
    "Jan 0.050323\n",
    "Feb 0.082143\n",
    "Mar 0.070968\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using multi-index on rows\n",
    "\n",
    "```python\n",
    "rain1314 = pd.concat([rain2013, rain2014], keys=[2013, 2014], axis=0)\n",
    "print(rain1314)\n",
    "Precipitation\n",
    "2013 Jan 0.096129\n",
    "Feb 0.067143\n",
    "Mar 0.061613\n",
    "2014 Jan 0.050323\n",
    "Feb 0.082143\n",
    "Mar 0.070968\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing a multi-index\n",
    "\n",
    "```python\n",
    "print(rain1314.loc[2014])\n",
    "Precipitation\n",
    "Jan 0.050323\n",
    "Feb 0.082143\n",
    "Mar 0.070968\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating columns\n",
    "\n",
    "```python\n",
    "rain1314 = pd.concat([rain2013, rain2014], axis='columns')\n",
    "print(rain1314)\n",
    "Precipitation Precipitation\n",
    "Jan 0.096129 0.050323\n",
    "Feb 0.067143 0.082143\n",
    "Mar 0.061613 0.070968\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a multi-index on columns\n",
    "\n",
    "```python\n",
    "rain1314 = pd.concat([rain2013, rain2014], keys=[2013, 2014], axis='columns')\n",
    "print(rain1314)\n",
    "2013 2014\n",
    "Precipitation Precipitation\n",
    "Jan 0.096129 0.050323\n",
    "Feb 0.067143 0.082143\n",
    "Mar 0.061613 0.070968\n",
    "\n",
    "print(rain1314[2013])\n",
    "Precipitation\n",
    "Jan 0.096129\n",
    "Feb 0.067143\n",
    "Mar 0.061613\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pd.concat() with dict\n",
    "\n",
    "```python\n",
    "rain_dict = {2013: rain2013, 2014: rain2014}\n",
    "rain1314 = pd.concat(rain_dict, axis='columns')\n",
    "print(rain1314)\n",
    "2013 2014\n",
    "Precipitation Precipitation\n",
    "Jan 0.096129 0.050323\n",
    "Feb 0.067143 0.082143\n",
    "Mar 0.061613 0.070968\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating vertically to get MultiIndexed rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing MultiIndexed DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating horizontally to get MultiIndexed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating DataFrames from a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer & inner joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using with arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(8).reshape(2, 4) + 0.1\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.arange(6).reshape(2,3) + 0.2\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.arange(12).reshape(3,4) + 0.3\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking arrays horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack([B, A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([B, A], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking arrays vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack([A, C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([A, C], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incompatible array dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([A, B], axis=0) # incompatible columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([A, C], axis=1) # incompatible rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population & unemployment data\n",
    "\n",
    "```python\n",
    "population = pd.read_csv('population_00.csv', index_col=0)\n",
    "\n",
    "unemployment = pd.read_csv('unemployment_00.csv', index_col=0)\n",
    "print(population)\n",
    "2010 Census Population\n",
    "Zip Code ZCTA\n",
    "57538 322\n",
    "59916 130\n",
    "37660 40038\n",
    "2860 45199\n",
    "\n",
    "print(unemployment)\n",
    "unemployment participants\n",
    "Zip\n",
    "2860 0.11 34447\n",
    "46167 0.02 4800\n",
    "1097 0.33 42\n",
    "80808 0.07 4310\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting to arrays\n",
    "\n",
    "```python\n",
    "population_array = np.array(population)\n",
    "print(population_array) # Index info is lost\n",
    "[[ 322]\n",
    "[ 130]\n",
    "[40038]\n",
    "[45199]]\n",
    "\n",
    "unemployment_array = np.array(unemployment)\n",
    "print(population_array)\n",
    "[[ 1.10000000e-01 3.44470000e+04]\n",
    "[ 2.00000000e-02 4.80000000e+03]\n",
    "[ 3.30000000e-01 4.20000000e+01]\n",
    "[ 7.00000000e-02 4.31000000e+03]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulating data as arrays\n",
    "\n",
    "```python\n",
    "print(np.concatenate([population_array, unemployment_array], axis=1))\n",
    "[[ 3.22000000e+02 1.10000000e-01 3.44470000e+04]\n",
    "[ 1.30000000e+02 2.00000000e-02 4.80000000e+03]\n",
    "[ 4.00380000e+04 3.30000000e-01 4.20000000e+01]\n",
    "[ 4.51990000e+04 7.00000000e-02 4.31000000e+03]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joins\n",
    "\n",
    "* Joining tables: Combining rows of multiple tables\n",
    "* Outer join\n",
    "    * Union of index sets (all labels, no repetition)\n",
    "    * Missing fields filled with NaN\n",
    "* Inner join\n",
    "    * Intersection of index sets (only common labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenation & inner join\n",
    "\n",
    "```python\n",
    "pd.concat([population, unemployment], axis=1, join='inner')\n",
    "\n",
    "2010 Census Population unemployment participants\n",
    "2860 45199 0.11 34447\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenation & outer join\n",
    "\n",
    "```python\n",
    "pd.concat([population, unemployment], axis=1, join='outer')\n",
    "\n",
    "2010 Census Population unemployment participants\n",
    "1097 NaN 0.33 42.0\n",
    "2860 45199.0 0.11 34447.0\n",
    "37660 40038.0 NaN NaN\n",
    "46167 NaN 0.02 4800.0\n",
    "57538 322.0 NaN NaN\n",
    "59916 130.0 NaN NaN\n",
    "80808 NaN 0.07 4310.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner join on other axis\n",
    "\n",
    "```python\n",
    "pd.concat([population, unemployment], join='inner', axis=0)\n",
    "\n",
    "Empty DataFrame\n",
    "Columns: []\n",
    "Index: [2860, 46167, 1097, 80808, 57538, 59916, 37660, 2860]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating DataFrames with inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resampling & concatenating DataFrames with inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Data\n",
    "\n",
    "Here, you'll learn all about merging pandas DataFrames. You'll explore different techniques for merging, and learn about left joins, right joins, inner joins, and outer joins, as well as when to use which. You'll also learn about ordered merging, which is useful when you want to merge DataFrames whose columns have natural orderings, like date-time columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging company DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging on a specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging on columns with non-matching labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging on multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining by Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing a joining strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Left & right merging on multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging DataFrames with outer join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordered merges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using merge_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using merge_asof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study - Summer Olympics\n",
    "\n",
    "To cement your new skills, you'll apply them by working on an in-depth study involving Olympic medal data. The analysis involves integrating your multi-DataFrame skills from this course and also skills you've gained in previous pandas courses. This is a rich dataset that will allow you to fully leverage your pandas data manipulation skills. Enjoy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medals in the Summer Olympics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Olympic edition DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading IOC codes DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building medals DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifying Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting medals by country/edition in a pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing fraction of medals per Olympic edition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing percentage change in fraction of medals won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping and plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building hosts DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging to compute influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting influence of host country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
